{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import cm\n",
    "from parse import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHUNKSIZE = 100000\n",
    "\n",
    "TRAIN_PATH        = \"../../data/train_StationPathInfo.csv\"\n",
    "TRAIN_PATH_EX     = \"../../data/train_StationPathInfoEx.csv\"\n",
    "TEST_PATH         = \"../../data/test_StationPathInfo.csv\"\n",
    "TEST_PATH_EX      = \"../../data/test_StationPathInfoEx.csv\"\n",
    "\n",
    "TRAIN_DATE        = \"../../data/train_date.csv\"\n",
    "TRAIN_NUMERIC     = \"../../data/train_numeric.csv\"\n",
    "TRAIN_CATEGORICAL = \"../../data/train_categorical.csv\"\n",
    "TEST_DATE         = \"../../data/test_date.csv\"\n",
    "TEST_NUMERIC      = \"../../data/test_numeric.csv\"\n",
    "TEST_CATEGORICAL  = \"../../data/test_categorical.csv\"\n",
    "\n",
    "SEED = 0\n",
    "CHUNKSIZE = 50000\n",
    "NROWS = 1200000\n",
    "\n",
    "ID_COLUMN = 'Id'\n",
    "TARGET_COLUMN = 'Response'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  L0_S0_F0  L0_S0_F2  L0_S0_F4  L0_S0_F6  L0_S0_F8  L0_S0_F10  L0_S0_F12  \\\n",
       "0   4     0.030    -0.034    -0.197    -0.179     0.118      0.116     -0.015   \n",
       "1   6       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "2   7     0.088     0.086     0.003    -0.052     0.161      0.025     -0.015   \n",
       "3   9    -0.036    -0.064     0.294     0.330     0.074      0.161      0.022   \n",
       "4  11    -0.055    -0.086     0.294     0.330     0.118      0.025      0.030   \n",
       "\n",
       "   L0_S0_F14  L0_S0_F16    ...     L3_S50_F4245  L3_S50_F4247  L3_S50_F4249  \\\n",
       "0     -0.032      0.020    ...              NaN           NaN           NaN   \n",
       "1        NaN        NaN    ...              NaN           NaN           NaN   \n",
       "2     -0.072     -0.225    ...              NaN           NaN           NaN   \n",
       "3      0.128     -0.026    ...              NaN           NaN           NaN   \n",
       "4      0.168     -0.169    ...              NaN           NaN           NaN   \n",
       "\n",
       "   L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  L3_S51_F4258  L3_S51_F4260  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_F4262  Response  \n",
       "0           NaN         0  \n",
       "1           NaN         0  \n",
       "2           NaN         0  \n",
       "3           NaN         0  \n",
       "4           NaN         0  \n",
       "\n",
       "[5 rows x 970 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_train_num = pd.read_csv(TRAIN_NUMERIC, nrows=NROWS, chunksize=CHUNKSIZE)\n",
    "chunk_test_num  = pd.read_csv(TEST_NUMERIC, nrows=NROWS, chunksize=CHUNKSIZE)\n",
    "chunk_train_cat = pd.read_csv(TRAIN_CATEGORICAL, nrows=NROWS, chunksize=CHUNKSIZE)\n",
    "chunk_test_cat  = pd.read_csv(TEST_CATEGORICAL, nrows=NROWS, chunksize=CHUNKSIZE)\n",
    "\n",
    "df_train_num = chunk_train_num.get_chunk(10)\n",
    "df_test_num  = chunk_test_num.get_chunk(10)\n",
    "df_train_cat = chunk_train_cat.get_chunk(10)\n",
    "df_test_cat  = chunk_test_cat.get_chunk(10)\n",
    "\n",
    "df_train_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通過ステーション情報・時刻情報を読み出す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tomonobu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 読み出す。\n",
    "TEST_START_TIME      = \"../../data/test_StartEndTime.csv\"\n",
    "TRAIN_START_TIME     = \"../../data/train_StartEndTime.csv\"\n",
    "\n",
    "df_train_bin = pd.read_csv(TRAIN_PATH, dtype='float32')\n",
    "df_test_bin  = pd.read_csv(TEST_PATH, dtype='float32')\n",
    "df_pass = pd.concat([df_train_bin, df_test_bin])\n",
    "\n",
    "df_start_train = pd.read_csv(TRAIN_START_TIME, dtype='float32')\n",
    "df_start_train = df_start_train.ix[:,['Id','StartTime','EndTime', 'Response']]\n",
    "df_start_test = pd.read_csv(TEST_START_TIME, dtype='float32')\n",
    "df_start_test['Response'] = -1\n",
    "df_time = pd.concat([df_start_train, df_start_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S32 の numeric, categorical とマージし、S32に限定して予想してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_one_sation_info(df_merge, station_id):\n",
    "    categorical_file_name = \"../../data/all_categorical_bitdec_station_\" + str(station_id) + \".csv\"\n",
    "    if os.path.exists(categorical_file_name):\n",
    "        df_cat = pd.read_csv(categorical_file_name, dtype='float32')\n",
    "        df_merge = pd.merge(df_merge, df_cat, on=\"Id\", how=\"left\", copy=False)\n",
    "    \n",
    "    numeric_train_file_name = \"../../data/train_numeric_station_\" + str(station_id) + \".csv\"\n",
    "    numeric_test_file_name  = \"../../data/test_numeric_station_\"  + str(station_id) + \".csv\"\n",
    "    if os.path.exists(numeric_train_file_name):\n",
    "        df_train_num = pd.read_csv(numeric_train_file_name, dtype='float32')\n",
    "        df_test_num  = pd.read_csv(numeric_test_file_name, dtype='float32')\n",
    "        df_num = pd.concat([df_train_num, df_test_num])    \n",
    "        df_merge = pd.merge(df_merge, df_num, on='Id', how='left', copy=False)\n",
    " \n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_analyze = pd.merge(df_pass, df_time, on='Id', how='left')\n",
    "df_analyze_S32 = df_analyze[df_analyze['L3_S32_D3852'] == 1]\n",
    "for station_id in range(39):\n",
    "    df_analyze_S32 = merge_one_sation_info(df_analyze_S32, station_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S1_D26</th>\n",
       "      <th>L0_S2_D34</th>\n",
       "      <th>L0_S3_D70</th>\n",
       "      <th>L0_S4_D106</th>\n",
       "      <th>L0_S5_D115</th>\n",
       "      <th>L0_S6_D120</th>\n",
       "      <th>L0_S7_D137</th>\n",
       "      <th>L0_S8_D145</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S36_F3938</th>\n",
       "      <th>L3_S37_F3944</th>\n",
       "      <th>L3_S37_F3946</th>\n",
       "      <th>L3_S37_F3948</th>\n",
       "      <th>L3_S37_F3950</th>\n",
       "      <th>L3_S38_F3954_bit_0</th>\n",
       "      <th>L3_S38_F3955_bit_9</th>\n",
       "      <th>L3_S38_F3952</th>\n",
       "      <th>L3_S38_F3956</th>\n",
       "      <th>L3_S38_F3960</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>616.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  L0_S0_D1  L0_S1_D26  L0_S2_D34  L0_S3_D70  L0_S4_D106  L0_S5_D115  \\\n",
       "0  116.0       0.0        0.0        0.0        0.0         0.0         0.0   \n",
       "1  146.0       1.0        1.0        0.0        1.0         0.0         1.0   \n",
       "2  166.0       0.0        0.0        0.0        0.0         0.0         0.0   \n",
       "3  293.0       1.0        1.0        1.0        0.0         0.0         1.0   \n",
       "4  616.0       1.0        1.0        1.0        0.0         0.0         1.0   \n",
       "\n",
       "   L0_S6_D120  L0_S7_D137  L0_S8_D145      ...       L3_S36_F3938  \\\n",
       "0         0.0         0.0         0.0      ...                0.0   \n",
       "1         0.0         1.0         1.0      ...                NaN   \n",
       "2         0.0         0.0         0.0      ...                0.0   \n",
       "3         0.0         1.0         1.0      ...                NaN   \n",
       "4         1.0         0.0         1.0      ...                0.0   \n",
       "\n",
       "   L3_S37_F3944  L3_S37_F3946  L3_S37_F3948  L3_S37_F3950  L3_S38_F3954_bit_0  \\\n",
       "0           0.0           0.0           0.0           0.0                 0.0   \n",
       "1           0.0           0.0           0.0           0.0                 0.0   \n",
       "2           0.0           0.0           0.0           0.0                 0.0   \n",
       "3           0.0           0.0           0.0           0.0                 0.0   \n",
       "4           0.0           0.0           0.0           0.0                 0.0   \n",
       "\n",
       "   L3_S38_F3955_bit_9  L3_S38_F3952  L3_S38_F3956  L3_S38_F3960  \n",
       "0                 0.0           NaN           NaN           NaN  \n",
       "1                 0.0           NaN           NaN           NaN  \n",
       "2                 0.0           NaN           NaN           NaN  \n",
       "3                 0.0           NaN           NaN           NaN  \n",
       "4                 0.0           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 1441 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyze_S32.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss, make_scorer\n",
    "\n",
    "def calc_mcc(cf_mat):\n",
    "    tn, fp, fn, tp = cf_mat.ravel()\n",
    "    if (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) == 0:\n",
    "        return 0\n",
    "    mcc = (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    return mcc\n",
    "\n",
    "def mcc_scorer(y_true, y_pred):\n",
    "    cf_mat = confusion_matrix(y_true, y_pred)\n",
    "    return calc_mcc(cf_mat)\n",
    "\n",
    "def separate_X_y(df):\n",
    "    X = df.drop(['Response'], axis=1)\n",
    "    y = df['Response']\n",
    "    return X, y\n",
    "\n",
    "def serach_best_threshold(y_pred_proba, y_test):\n",
    "    vals = []\n",
    "    thresholds = []\n",
    "    for i in range(1, 90):\n",
    "        threshold = i / 100.0\n",
    "        y_pred = (y_pred_proba[:, 1] > threshold).astype(int)\n",
    "        cf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        mcc = calc_mcc(cf_mat)\n",
    "        vals.append(mcc)\n",
    "        thresholds.append(threshold)\n",
    "    best_threshold = thresholds[np.argmax(vals)]\n",
    "    best_mcc = np.max(vals)\n",
    "    print(best_threshold, best_mcc)\n",
    "    return best_mcc, best_threshold \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_with_r_forest(df, param):\n",
    "    kf = KFold(n_splits=3, random_state=2, shuffle=True)\n",
    "    vals = []\n",
    "    thresholds = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(df):\n",
    "        data_tr   = df.iloc[train_index]\n",
    "        data_val  = df.iloc[test_index]\n",
    "        \n",
    "        X_train, y_train = separate_X_y(data_tr)\n",
    "        xgb_model = xgb.XGBClassifier(max_depth=param['max_depth'],\n",
    "                                    subsample=param['subsample'],\n",
    "                                    colsample_bytree =param['colsample_bytree'],\n",
    "                                    scale_pos_weight=param['scale_pos_weight'])\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        \n",
    "        X_test, y_test = separate_X_y(data_val)\n",
    "        y_pred_proba = xgb_model.predict_proba(X_test)\n",
    "        mcc, threshold = serach_best_threshold(y_pred_proba, y_test)\n",
    "        vals.append(mcc)\n",
    "        thresholds.append(threshold)\n",
    "        del X_train, y_train\n",
    "        del data_tr, data_val\n",
    "    return np.mean(vals), np.mean(threshold)\n",
    "\n",
    "def grid_search(df, param_grid):\n",
    "    scores = []\n",
    "    params = []\n",
    "    thresholds = []\n",
    "    for max_depth in param_grid['max_depth']:\n",
    "        for subsample in param_grid['subsample']:\n",
    "            for colsample_bytree in param_grid['colsample_bytree']:\n",
    "                for scale_pos_weight in param_grid['scale_pos_weight']:\n",
    "                    param = {'max_depth': max_depth,\n",
    "                                'subsample': subsample,\n",
    "                                'colsample_bytree': colsample_bytree,\n",
    "                                'scale_pos_weight': scale_pos_weight\n",
    "                            }\n",
    "                    score, threshold = train_with_r_forest(df, param)\n",
    "                    print(score, threshold)\n",
    "                    scores.append(score)\n",
    "                    params.append(param)\n",
    "                    thresholds.append(threshold)\n",
    "    # ベストスコアのパラメータを使って再トレーニング\n",
    "    best_estimator = params[np.argmax(scores)]\n",
    "    best_threshold = thresholds[np.argmax(thresholds)]\n",
    "    xgb_model = xgb.XGBClassifier(max_depth=best_estimator['max_depth'],\n",
    "                                subsample=best_estimator['subsample'],\n",
    "                                colsample_bytree =best_estimator['colsample_bytree'],\n",
    "                                scale_pos_weight=best_estimator['scale_pos_weight'])\n",
    "    X_train, y_train = separate_X_y(df)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    del X_train, y_train\n",
    "    return xgb_model, best_estimator, best_threshold\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_rf_parameter(df, params, undersample_rate):\n",
    "    print(df.shape)\n",
    "    df = df[(df['Response'] == 0) | (df['Response'] == 1)]\n",
    "    df = df.drop(['Id'], axis=1)\n",
    "    print(df.shape)\n",
    "    df_train, df_test = train_test_split(df, random_state=33)\n",
    "    \n",
    "    df_train_ok   = df_train[df_train['Response'] == 0]\n",
    "    df_train_ng   = df_train[df_train['Response'] == 1]\n",
    "    df_train_ok_sample = df_train_ok.sample(frac = undersample_rate)\n",
    "    df_train = pd.concat([df_train_ok_sample, df_train_ng])\n",
    " \n",
    "    rf, params, threshold = grid_search(df_train, params)\n",
    "    X_test, y_test = separate_X_y(df_test)\n",
    "    y_pred_proba = rf.predict_proba(X_test)\n",
    "    mcc, threshold = serach_best_threshold(y_pred_proba, y_test)\n",
    "    print(mcc)    \n",
    "    return rf, params, threshold\n",
    "\n",
    "\n",
    "def train_and_predict_submission(df, param, threshold, undersample_rate):\n",
    "    df_train_ok   = df[df['Response'] == 0]\n",
    "    df_train_ng   = df[df['Response'] == 1]\n",
    "    df_test       = df[df['Response'] == -1]\n",
    "    \n",
    "    df_train_ok_sample = df_train_ok.sample(frac = undersample_rate)\n",
    "    df_train = pd.concat([df_train_ok_sample, df_train_ng])\n",
    "    df_train_balance = df_train.drop(['Id'], axis=1)\n",
    "    df_test_ex_id    = df_test.drop(['Id'], axis=1)\n",
    "\n",
    "    del df_train_ok\n",
    "    del df_train_ng\n",
    "    \n",
    "    X_train, y_train = separate_X_y(df_train_balance)\n",
    "    xgb_model = xgb.XGBClassifier(max_depth=param['max_depth'],\n",
    "                                subsample=param['subsample'],\n",
    "                                colsample_bytree =param['colsample_bytree'],\n",
    "                                scale_pos_weight=param['scale_pos_weight'])\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    X_test, y_test = separate_X_y(df_test_ex_id)\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)\n",
    "    y_pred = (y_pred_proba[:, 1] > threshold).astype(int)\n",
    "      \n",
    "    df_result_add = pd.DataFrame(columns=['Id', 'Response'])\n",
    "    df_result_add.loc[:, 'Id']       = df_test['Id'].values\n",
    "    df_result_add.loc[:, 'Response'] = y_pred\n",
    "    \n",
    "    return xgb_model, df_result_add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48678, 1441)\n",
      "(24543, 1440)\n",
      "0.21 0.497112066566\n",
      "0.21 0.476451397174\n",
      "0.29 0.461385917277\n",
      "0.478316460339 0.29\n",
      "0.35 0.495541544535\n",
      "0.36 0.478045637547\n",
      "0.31 0.476067135437\n",
      "0.48321810584 0.31\n",
      "0.46 0.487645776108\n",
      "0.36 0.47404835801\n",
      "0.36 0.457726102838\n",
      "0.473140078985 0.36\n",
      "0.13 0.474001046442\n",
      "0.1 0.462189091829\n",
      "0.06 0.447461571166\n",
      "0.461217236479 0.06\n",
      "0.14 0.465653856123\n",
      "0.1 0.452393080906\n",
      "0.06 0.447010710978\n",
      "0.455019216003 0.06\n",
      "0.11 0.452958754886\n",
      "0.16 0.467329604943\n",
      "0.07 0.437421477972\n",
      "0.452569945934 0.07\n",
      "0.33 0.464532270671\n",
      "0.464532270671\n",
      "{'max_depth': 5, 'subsample': 0.95, 'colsample_bytree': 1.0, 'scale_pos_weight': 4}\n",
      "threshold: 0.33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Grid Search\n",
    "params={'max_depth': [5, 10],\n",
    "        'subsample': [0.95],\n",
    "        'colsample_bytree': [1.0],\n",
    "        'scale_pos_weight': [2, 4, 8]\n",
    "}\n",
    "model, best_param, best_threshold = train_rf_parameter(df_analyze_S32, params, 1)\n",
    "print(best_param)\n",
    "print('threshold:', best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "model, df_result_S32 = train_and_predict_submission(df_analyze_S32, best_param, best_threshold, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ...,  0.00202532,\n",
       "        0.00556962,  0.01721519], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame(columns=['name', 'importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_feature_importance.loc[:, 'importance'] = model.feature_importances_\n",
    "df_feature_importance.loc[:, 'name'] = np.array(df_analyze_S32.drop(['Id','Response'], axis=1).columns)\n",
    "df_feature_importance.sort_values('importance', ascending=False)\n",
    "del df_analyze_S32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Station32 を通過していないサンプルで解析する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更にStation29を通過しているものとそれ以外に分離。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_analyze_S28_exS32 = df_analyze[(df_analyze['L3_S29_D3316'] == 1) & (df_analyze['L3_S32_D3852'] == 0)]\n",
    "\n",
    "print(df_analyze.shape)\n",
    "print(df_analyze_S28_exS32.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature を足す。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 39):\n",
    "    df_analyze_S28_exS32 = merge_one_sation_info(df_analyze_S28_exS32, i)\n",
    "\n",
    "df_analyze_S28_exS32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S1_D26</th>\n",
       "      <th>L0_S2_D34</th>\n",
       "      <th>L0_S3_D70</th>\n",
       "      <th>L0_S4_D106</th>\n",
       "      <th>L0_S5_D115</th>\n",
       "      <th>L0_S6_D120</th>\n",
       "      <th>L0_S7_D137</th>\n",
       "      <th>L0_S8_D145</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S36_F3938</th>\n",
       "      <th>L3_S37_F3944</th>\n",
       "      <th>L3_S37_F3946</th>\n",
       "      <th>L3_S37_F3948</th>\n",
       "      <th>L3_S37_F3950</th>\n",
       "      <th>L3_S38_F3954_bit_0</th>\n",
       "      <th>L3_S38_F3955_bit_9</th>\n",
       "      <th>L3_S38_F3952</th>\n",
       "      <th>L3_S38_F3956</th>\n",
       "      <th>L3_S38_F3960</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1441 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  L0_S0_D1  L0_S1_D26  L0_S2_D34  L0_S3_D70  L0_S4_D106  L0_S5_D115  \\\n",
       "0   4.0       1.0        1.0        1.0        0.0         1.0         0.0   \n",
       "1   6.0       0.0        0.0        0.0        0.0         0.0         0.0   \n",
       "2   7.0       1.0        1.0        1.0        0.0         0.0         1.0   \n",
       "3   9.0       1.0        1.0        1.0        0.0         1.0         0.0   \n",
       "4  11.0       1.0        1.0        0.0        1.0         1.0         0.0   \n",
       "\n",
       "   L0_S6_D120  L0_S7_D137  L0_S8_D145      ...       L3_S36_F3938  \\\n",
       "0         0.0         1.0         1.0      ...                NaN   \n",
       "1         0.0         0.0         0.0      ...                NaN   \n",
       "2         1.0         0.0         1.0      ...                NaN   \n",
       "3         0.0         1.0         1.0      ...                0.0   \n",
       "4         0.0         1.0         1.0      ...                0.0   \n",
       "\n",
       "   L3_S37_F3944  L3_S37_F3946  L3_S37_F3948  L3_S37_F3950  L3_S38_F3954_bit_0  \\\n",
       "0           0.0           0.0           0.0           0.0                 0.0   \n",
       "1           0.0           0.0           0.0           0.0                 0.0   \n",
       "2           0.0           0.0           0.0           0.0                 0.0   \n",
       "3           0.0           0.0           0.0           0.0                 0.0   \n",
       "4           0.0           0.0           0.0           0.0                 0.0   \n",
       "\n",
       "   L3_S38_F3955_bit_9  L3_S38_F3952  L3_S38_F3956  L3_S38_F3960  \n",
       "0                 0.0           NaN           NaN           NaN  \n",
       "1                 0.0           NaN           NaN           NaN  \n",
       "2                 0.0           NaN           NaN           NaN  \n",
       "3                 0.0           NaN           NaN           NaN  \n",
       "4                 0.0           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 1441 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analyze_S28_exS32.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2190476, 1441)\n",
      "(1095118, 1440)\n",
      "0.37 0.271811644448\n",
      "0.38 0.279417152451\n",
      "0.37 0.260841289743\n",
      "0.270690028881 0.37\n",
      "0.52 0.269047793083\n",
      "0.44 0.265773865941\n",
      "0.45 0.255525664407\n",
      "0.26344910781 0.45\n",
      "0.62 0.257148566708\n",
      "0.63 0.259306285155\n",
      "0.62 0.253338906226\n",
      "0.256597919363 0.62\n",
      "0.76 0.201773088334\n",
      "0.201773088334\n",
      "{'max_depth': 10, 'subsample': 0.95, 'colsample_bytree': 1.0, 'scale_pos_weight': 2}\n",
      "threshold: 0.76\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Grid Search\n",
    "params={'max_depth': [10],\n",
    "        'subsample': [0.95],\n",
    "        'colsample_bytree': [1.0],\n",
    "        'scale_pos_weight': [2, 4, 8]\n",
    "}\n",
    "model_ex_s32, best_param_ex_S32, best_threshold_ex_S32 = train_rf_parameter(df_analyze_S28_exS32, params, 0.1)\n",
    "print(best_param_ex_S32)\n",
    "print('threshold:', best_threshold_ex_S32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_model_and_param(model, name):\n",
    "    filename = name + '.model_sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "model_param_ex_s32 = {'model': model_ex_s32, 'param': best_param_ex_S32, 'threshold': best_threshold_ex_S32}\n",
    "save_model_and_param(model_param_ex_s32, 'ex_s_32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model_ex_s32\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " undersample しない場合の記録。スレッショルドの値が安定しない。\n",
    "(2190476, 243)\n",
    "(1095118, 242)\n",
    "0.08 0.0905819923564\n",
    "0.12 0.111272832291\n",
    "0.1 0.103684351704\n",
    "0.101846392117 0.1\n",
    "0.15 0.0956803319768\n",
    "0.15 0.104176523291\n",
    "0.16 0.10149169362\n",
    "0.100449516296 0.16\n",
    "0.2 0.107243310696\n",
    "0.4 0.104551146764\n",
    "0.37 0.1046494497\n",
    "0.105481302387 0.37\n",
    "0.21 0.124588700736\n",
    "0.124588700736\n",
    "{'max_depth': 10, 'subsample': 0.95, 'colsample_bytree': 1.0, 'scale_pos_weight': 8}\n",
    "threshold: 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_result_S28_ex_S32_all, df_result_S28_ex_S32 = train_and_predict_submission(df_analyze_S28_exS32, best_param_ex_S32, best_threshold_ex_S32, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<6/27 朝>\n",
    "Subsample = 0.2\n",
    "\n",
    "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1.0,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=2, seed=0, silent=True, subsample=0.95)\n",
    "       \n",
    "<Subsampleなし>\n",
    "\n",
    "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1.0,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=20,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=2, seed=0, silent=True, subsample=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128341, 56)\n"
     ]
    }
   ],
   "source": [
    "df_analyze_exS28     = df_analyze[(df_analyze['L3_S29_D3316'] == 0) & (df_analyze['L3_S32_D3852'] == 0)]\n",
    "print(df_analyze_exS28.shape)\n",
    "\n",
    "for i in range(0, 29):\n",
    "    df_analyze_exS28 = merge_one_sation_info(df_analyze_exS28, i)\n",
    "\n",
    "for i in range(39, 52):\n",
    "    df_analyze_exS28 = merge_one_sation_info(df_analyze_exS28, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128341, 1347)\n",
      "(64086, 1346)\n",
      "0.33 0.172549857579\n",
      "0.2 0.138958181279\n",
      "0.42 0.153907909905\n",
      "0.155138649588 0.42\n",
      "0.54 0.162926829876\n",
      "0.22 0.126609678196\n",
      "0.47 0.153907909905\n",
      "0.147814805992 0.47\n",
      "0.55 0.199550027553\n",
      "0.44 0.155655367038\n",
      "0.32 0.122552764391\n",
      "0.159252719661 0.32\n",
      "0.69 0.15273921855\n",
      "0.8 0.1470271841\n",
      "0.65 0.145510434951\n",
      "0.148425612534 0.65\n",
      "0.63 0.144734287054\n",
      "0.86 0.1470271841\n",
      "0.63 0.132602187421\n",
      "0.141454552859 0.63\n",
      "0.89 0.162926829876\n",
      "0.81 0.155655367038\n",
      "0.32 0.153125378877\n",
      "0.157235858597 0.32\n",
      "0.73 0.144734287054\n",
      "0.2 0.138958181279\n",
      "0.89 0.145510434951\n",
      "0.143067634428 0.89\n",
      "0.88 0.144734287054\n",
      "0.26 0.138958181279\n",
      "0.16 0.144181253771\n",
      "0.142624574035 0.16\n",
      "0.06 0.134179155678\n",
      "0.23 0.138958181279\n",
      "0.13 0.136605181258\n",
      "0.136580839405 0.13\n",
      "0.37 0.214320591483\n",
      "0.214320591483\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Grid Search\n",
    "params={'max_depth': [5, 10, 20],\n",
    "        'subsample': [0.95],\n",
    "        'colsample_bytree': [1.0],\n",
    "        'scale_pos_weight': [2, 4, 8]\n",
    "}\n",
    "model_exS28, best_param_ex_S28, best_threshold_ex_S28= train_rf_parameter(df_analyze_exS28, params, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_result_ex_S28_all, df_result_ex_S28 = train_and_predict_submission(df_analyze_exS28,  best_param_ex_S28,best_threshold_ex_S28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result_ex_S28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.concat([df_result_S32, df_result_S28_ex_S32, df_result_ex_S28]).sort_values('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result['Id'] = df_result['Id'].astype('int32')\n",
    "df_result.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv(\"../../submission/submit_20180713_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
